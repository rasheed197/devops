# S3 INTRODUCTION 

Welcome to the Amazon S3 session.

In this session, we will be learning Amazon S3 service, `Simple Storage Service`. As the name says, it's really very simple to use and there are really many, many, many use cases for S3.

S3 is one of the most popular service of AWS and also one of the oldest one. Let's see, what is S3?

## WHAT IS S3

Amazon Simple Storage Service (Amazon S3) is storage for the internet. You can use Amazon S3 to store and retrieve any amount of data at any time, from anywhere on the web.

So S3 is a storage service and you can access it over the internet. You can store any amount of data in S3 bucket at any time, and you can access from anywhere.

So as of now, think of it as like Google Drive or Dropbox, but it's much more than that with many, many features.

## S3 BASIC

- It's an object-based storage.

    Again, just like Google Drive or Dropbox where you can upload your files and access them from anywhere like your documents, pictures, videos, etc.

- Data is replicated across multiple facilities.

    When you upload any data into S3 bucket. bucket is really the top level storage. It's like a folder in the S3 bucket, the top level folder. When you upload the data in the bucket, the data is replicated in multiple facilities. 

- Unlimited storage
    
    There is no limit, you can store unlimited amount of data. 

- Amazon S3stores data as objects within buckets

    So the data that you store is object and the storage is called a bucket.

- Bucket name has to be unique

    because we will be getting an endpoint to access it and then that endpoint will have the name of the bucket. So it has to be unique on the internet. 


A `bucket` is a logical unit of storage in AWS. It's a logical container where you store the data

An `object storage` is a computer data storage architecture that manages data as objects. In short, an object is the data that you're storing. Like your file, document, picture, video will be an object.

So you have properties at the bucket level, you have properties at the object level. You can set permission at both levels and it's really simple to do. You just access the S3 service, you create a bucket, if you want you can create folder to organize it, and then you can upload your object and then you can access it from anywhere. And again, that's based on if you have given the permission to access it publicly or internally or for some IAM users. 

There are different ways of accessing data on your S3 bucket. One common, very, very common use case of S3 bucket is EC2 instances which are running some service, let's say web service, any application service, they want to store some file-based data. They can use S3 bucket. So developers will program in their application that the data is getting stored in S3 bucket and not in some folder locally.

So yeah, this may seem like EFS through this architectural design. But in EFS, we mount the file system at the operating system level. So we get a folder at the operating system level where we store the data. But S3, we're going to programmatically access through our application.

You can also mount S3 bucket to a folder, but that comes through a different driver, `S3 FS`. So that's one very common use case, but there are many, many use cases we are going to see in the exercise.

## STORAGE TYPE / CLASS IN S3 BUCKET

The different storage classes, or you can say storage types in S3 bucket,

1. S3 Standard
   This is the most common one. General Purpose storage of frequently accessed data. Fast access and object replication in multi AZ.

    So if you select this storage type, then the data access will be fast and object will be replicated in multiple availability zones and you will be charged accordingly for that. 

2. S3 IA - Infrequent Access 

    Long-lived, but less frequently accessed data.Slow access, object replication in multi AZ.

    If you don't access the data so frequently, maybe you're storing it to access the data once in a day or once in a week or few times in a week, it's not a continuous access, then you can save some cost and you can select S3 infrequent access. 

    Here, the data access will be slow, but the object is still getting replicated in multiple availability zones and the replication happens automatically, we don't really need to do anything, we don't need to set anything for that. And this is in multiple availability zones, not the region. This is so you don't lose your data.

3. S3 One Zone-IA Infrequent Access
   
    This is for data that is access less frequently, but require rapid access when needed. Slow access, no object replication.

    Where you really don't care about the data durability. Maybe you already have it somewhere stored or it's not such critical data. 

    So you can save some money, you can select S3 One Zone Infrequent Access. So no redundancy, the data is not replicated and the data access will be slower. Now when I say slower, infrequent access, I'm comparing it with S3 standard.

4. S3 Intelligent Tiering

    Automatically moves data to the most cost effective tier. And again, this happens automatically, you don't need to do anything.

5. S3 Glacier

    Low cost storage class for data archiving.

    It is really a very low cost storage and usually, we do the data archiving on that, where we dump the data which we rarely access, maybe once in a year for audit or maybe you have some compliance where you need to store the data for a particular period of time, let's say one year, two year, and then you can delete the data.

    So such kind of data which you rarely going to access, we put in S3 Glacier and save some money.

6 S3 Glacier Deep Archive

    Lowest cost storage, retrieval time of 12hrs.

    This is the lowest cost storage and the retrieval time can be up to 12 hours. So you want to store long, long time data, like decades where you very rarely, maybe you are going to access it sometimes like old medical records or some government records.

And there is also one more that has come up again back, which I'm going to show you.

## LIFECYCLE POLICIES 

Now while you're uploading object, you can decide what storage type or you can also set lifecycle policy that can move your object from one storage type to another based on its age.

So let's say for an example, your data that you uploaded is aged 30 days and you set a policy that after 30 days, move my object from `S3 Standard` to `S3 Infrequent Access`. So it'll be automatically shifted to Infrequent Access storage type. And let's say, you said after 30 more days, so total 60 days, move it to `One Zone Infrequent Access`. Or maybe you have set after 90 days, just move it to `Amazon Glacier`.

So this lifecycle policy we usually set it on logs archive, and you can also set expiry also, you can set that after one year, delete all this data. So the data is automatically shifting from one storage type to another based on its age and then finally getting deleted. So this is just to save your cost.

There is this table from AWS documentation, of all the S3 storage type; S3 Standard Intelligent Tiering, Infrequent Access, One Zone Infrequent Access, Glacier, and Glacier Deep Archive.

`Durability` is 99.99999999999%. So anything you select, you have the durability.

For `Availability`, most of them are 99.99%. Okay, some of them are 99.9 and then 99.5 for S3 One Zone Infrequent Access

`Availability SLA` is almost same with an extra .9 for S3 standard.

`Availability Zones` it's going to be doing replications as you know, at minimum three zones, three subfacilities for intelligent tiering, three for S3, infrequent access three, but for S3 One Zone Infrequent Access, it's just one availability zone. So here, data is really not getting replicated in many zones.

`Retrieval fee`, if you check for S3 Standard, Intelligent Tiering there is no retrieval fees specified because it's you know, fast access, but for others, you have it charged on per GB. So this should be useful when you really want to decide which storage type to select for your objects.

## S3 CHARGES

Now let's finally discuss about the three charges.

1. `Storage`: first of all, you get charged on the storage, the amount of data you're storing.

2. `Reqiests`: the number of requests you're sending, IO

3. `Tiers`: what storage type you selected, what tier you selected, based on that, there'll be a charge.

4. `Data transfer` 

5. `Region replication`: There is an option to replicate your S3 bucket from one region to other region. You can set that up and there'll be extra charges for that. Mostly, we do that for disaster recovery or maybe we want to sync data between two S3 buckets, which are in different region.

So now let's go and access this simple storage service and let's see some use cases. Open AWS console, search for `S3` and open it. Okay, so now, we will do very simple exercise. We will create a S3 bucket. We'll upload few objects or files into it. We'll see how they are private and how we can make it public based on our use case, and along the line, we will see some options that S3 provides.

Once we get comfortable with S3, then we'll see into some more advanced options in S3. So let's say `Create bucket`.

Okay, so when you create a bucket, you get few options, `General purpose`. So most of the use cases uses general purpose, but now you have a new one `Directory`, which is for low latency. `Directory` provides a faster processing, but it's just available in one single availability zone.

Check the region, wherever you are in whichever region, you have selected already, it's going to create the S3 bucket in that region. But S3 is a global service, it is accessible from everywhere, but based on your use case, you can select the right region based on where the user is or users are located, so like that.

`Bucket name`: bucket name needs to be unique globally. So give a unique bucket name. 

Now let's come down, scroll down, `Object ownership`, we will keep it disabled. So S3 can also provide access based on access control list. That means the AWS account users can be given the access to the S3 bucket, but most of the bucket permission will be through policies, we'll talk about that later. So by default, it's going to be disabled, but when we want to make the S3 bucket public, then we need to enable `ACLs`. We'll see that.

Okay, now keep this in mind, whenever you upload any object in the S3 bucket, it's by default, private, it cannot be accessed publicly. Even if you want to make it public, you cannot do it because by default, all the public access is blocked `Block all public access` is checked mark by default. It's an extra level of safety or security you can say.

Now, it's not like AWS is forcing you to keep everything private. You may have many use cases where you want to make the S3 bucket public, when you want to host publicly available images, documents, or even websites, you need to make it public. But AWS is just making sure that accidentally, you don't make your data public. And we'll see this in a moment once we create the bucket and we upload the object.

`Bucket versioning`, so there's one very common question that I get asked by the client or many people ask me this.

**What happens if you know, delete the data in the S3 bucket? Can we recover it?**

It is based on if you have enabled versioning. If you enable versioning, it's super easy, you just see the older version and you can just revert it. Sure, there are other ways in architecture, but this is the easier one and we will enable it. We have some use cases that we'll talk about. I need to show you how to, you know, recover the data. So let's enable the versioning.

`Encryption`, by default, S3 is forcing you to encrypt your data. This was not the case earlier, you had an option to have unencrypted data also, but now, there is encryption, and what kind of encryption do you want?

- `Server-side encryption with Amazon S3 managed keys`: so the encryption keys will be managed by Amazon S3. It's the cheapest option.

- Then you have `encryption with KMS`. So you can create your own encryption key by using AWS KMS service. Mind you, it's not free. And even if you create it, you cannot just delete the KMS keys. There is a seven days of period from where you disable it, but you have the ownership of the keys. 

    This is mostly used for compliance. You don't want to give, you know, encryption decryption keys to AWS, you want to keep the keys with yourself. So you can, you know, go with KMS.

- Then you have `dual layer of encryption`. 

And again, the pricing will increase for our exercise. We'll keep it just SSE-S3 and we will just say `Create bucket`.

Okay, the bucket is created. Click on it, open it, and upload some files. So I'm going to say `Add files`, and I'm going to select some PDF from my desktop.

Now while you upload any object,you can select the storage class. If you go to the `Properties` while uploading the object, you'll see the properties and you can select the `Storage class` of that object.

`Standard` is by default, and then you have all the options that we already discussed in the introduction.

You also have an option to decide the encryption key for the object. Now, encryption is there on the S3 bucket and whatever key you used for it. You can specify a different encryption key for the object that you're uploading. But we'll just keep it `Do not specify an encryption key` and we'll say `Upload`.

Okay, now I want you to pause the lecture and go through all the different tabs and look at all the different settings of the S3 bucket. Also, click on the object and look at the different options available for the object as well.

Okay, so let's start talking about the access of the object. So by default, any object that you upload in the S3 bucket is private by default. It cannot be made public. Now there is an `Open` option over here. This is going to open the object with the AWS user privileges. So you know, the user that I logged in on this AWS console, and it's the same user who uploaded the object.

So the owner can open the object, read access basically. It opens on the browser, but that does not mean it's publicly accessible, I'll show you. If you click on the object and there is `Object URL`, that's the link, copy that and put it on the browser, this is the publicly available URL for this object, and you see that it says access denied.

Now we'll see how we can make it public. Now this is just an exercise. It does not mean that you have to make every object public, it's based on the use case. Like for example, your hosting website or an application created by the developer needs access to publicly available images or videos, then you need to make those object public, otherwise, no.

So how to make it public? It's pretty simple.

Select the object or multiple objects, go to `Action` and if you scroll down, you will get option here, `Make public using ACL`, but you see it's grayed out because ACL is disabled on the bucket. So you cannot make it public through ACLs.

First thing is you need to go to the `Permissions`, you need to go to `Object ownership`,and click `Edit`. and you need to enable the ACLs, access control list `ACLs enabled`, and say I acknowledge and say Save Changes.

Now ACLs are enabled, you can make the object public through ACL. Once again, let's go to the bucket, select our object go to `Action -> Make public using ACL`.

And now you should get an error when you click on `Make public`. That is because all the public access on the S3 bucket is disabled.

Yeah, while creating the bucket, we see that option, right? We can go to go to our S3 bucket and go to `Permissions`. If you scroll down, you see `Block public access`, it's on. So click on `Edit` and you uncheck that.

Now only do it if it's really required, otherwise just keep it blocked. Now we are seeing a use case, right? So we unblock it, `Save changes`.

So we enabled the ACL, we disable this option 'Block public access`. Now, we are going to make the object public using ACL,

So go to `Action -> Make public using ACL -> Make public`. Okay, now let's go to that URL and let's refresh it, from the publicly available URL, we are able to access the object from the internet.

Okay, let's upload one more object. Say `Upload -> Add files`, and I will select the file I want to add.

Okay, now while I'm uploading, let's again look at all the options. 

First, the `Destination details`. So `Bucket versioning` is enabled, what is the encryption of the bucket? So those are the details.

`Permissions`, so you can say `Choose from predefined ACLs`. So we already enabled the ACLs. You can also make it public read access. I want to show you that if the object is private, even though the bucket is public, the object will be private, but if you want, you can make it public that I want to show you. So just keep it as `Private`.

Once again, `Properties`, you can change the storage class. Maybe I want to choose `One Zone Infrequent Access`.

And `Encryption`, we'll keep it as it is and say `Upload`.

Okay, so this is the second object. Let's click on that and let's get its URL, and put it in the browser. You see access denied, even though bucket is public, ACLs are enabled, but the object is still private. So we know how to make it public. 

Another way to make it public, I can just go to `Permissions`. We can just go to the permissions of the object, click `Edit`, and check mark `Everyone read`. You can do it this way too, but let's just do the simple option that is provided.

Select the object go to `Action -> Make public using ACL -> Make public`. Okay, so the object is made public. Now let's refresh this page. There you go.

Okay, so those were some simple use cases and exercises.

In the next lecture, we will see how we can host a website on the S3 bucket. Yes, it's possible, it's very easy. And with that, we'll see some other options available or features available with the S3 bucket.

So wrap this up and join me in the next lecture.


