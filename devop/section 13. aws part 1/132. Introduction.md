# Introduction

Welcome to the project. This is an AWS cloud computing project. The name of this project is `Lift and shift application workload`, and we're going to lift our application, the vprofile and shift it on AWS cloud.

Let's understand about this project, In previous project, we have seen a multi-tier Web application stack vprofile by using Vagrant .In this project, we are going to host and run it on AWS cloud for production. And we're going to use a lift and shift strategy for this.

After going through this project, you will learn how to run application workload on AWS cloud by using `Lift and shift strategy`. 

Let's understand the scenario. We have, let's say, application services, which are running on physical or virtual machines, there could be various services like databases services like Postgres, Oracle, application services like Tomcat, even LAMP Stack, DNS services and various kinds of services that powers our application. And we have all this work in our data center.

So, so many servers running varieties of services on your local data centre. To manage all this, you will need multiple teams working around the clock. We will need virtualization team for running virtualization platform, data center, operations team for data centre & related operations work, monitoring team to monitor 24/7 and sys admin team, of course.

## PROBLEM

- Managing all these services, servers and teams is complex.

- It becomes more complex if you want to scale up or scale down, which needs to be done very regularly.

- There's a huge cost for procuring all these resources and also regular maintenance cost.

- Most of the processes in this will be manual.

- If you have a virtualization layer on top of it, it is possible to automate those things, but it's really difficult to do it and also to maintain it.

- And not to mention all these things are very time consuming.

## SOLUTION

- Solution to all this problem is to have a cloud computing setup.
    
    So instead of running our workload in our data center, we run it on a cloud computing platform that we don't pay for the upfront cost for procuring the resource. 

- We pay as we go. Consuming infrastructure as a service. Just like electricity.

- We get flexibility, it's elastic in nature, we can scale out or scale in and really control our cost.

- So managing infrastructure becomes easier.

- And most important, we can do automation, we can automate each and every step and process to avoid human errors and save our time, of course.

## AWS SERVICES

We're using AWS, cloud computing, and we'll see what all the services that we are going to use in this project, starting with 

- EC2 Instances: EC2 instances will be our VMs for Tomcat, rabbitmq, Memcache and mysql servers. 

- Elastic Load Balancer (ELB): We'll also be using elastic load balancer, which will be replacement of our Nginx service.

- Autoscaling: We'll be using autoscaling service, which will automatically scale out and scale in our EC2 instances, which will automatically control our resources and also our cost.

- S3/EFS: For storage, we'll be using S3 or EFS for shared storage

- Route 53: for a private DNS service.

Along with these we will be using few more services like IAM, ACM, EBS etc.

## OBJECTIVES 

Let's make sure our objectives are clear.

- We want a flexible infrastructure, 

- No Upfront Cost: we want pay as we go model.

- Modernize Effectively: We would like to modernize our application more effectively by using AWS services.

- IAAC: we also want automation. Infrastructure as a code.

## ARCHITECTURE OF AWS SERVICE FOR THE PROJECT

Now we will see architectural design of AWS set up that we will be creating. We are using 

- EC2 Instances

- Elastic Load Balancer

- Autoscaling

- S3/EFS for shared storage.

- Amazon Certificate Manager and 

- Route 53 service

Well, this (vprofile.jpg) is the stack from our previous project. We had all the service on virtual machines on our computer, Nginx, Apache, Tomcat, RabbittMQ, Memcache and MySQL. We are going to shift this stack on AWS Cloud. Once we have our stack on AWS Cloud, our architectural design will be like this.

- Users will access our website by using a URL and that URL we be pointing to an end point. This entry will be mentioned in GoDaddy DNS.

- User browsers or the app will use this end point to connect to the load balancer, by using https

- Certificate for https encryption will be mentioned in Amazon Certificate Manager (ACM) Service.

- So users will access application load balancer endpoint. Our load balancer will be in a security group and will only allow https traffic.

- And then our application load balancer, will route the request to Tomcat instances. 

- Apache tomcat service, will be running on some set of instances which will be managed by our autoscaling group. So as for high or low load, these instances capacity will be scaled out or scaled in.

- These EC2 instances where Tomcat is running, will be in a separate security group and will only allow traffic on Port 8080 only from a load balancer.

- We know our vprofile application sits on Tomcat instance. We have seen this in our previous project. 

- And our application needs backend servers, which are MySQL, Memcache and RabbitMQ. Information of backend services or the backend server IP address will be mentioned in Route 53 private DNA zone.

- So Tomcat instances will access backend server with a name which will be mentioned in Route 53 Private dns where the private IP address of our backend server will be mentioned.

These backend EC2 instances, which will be running mysql, RabbitMQ, Memcache will be in a separate security group. So the AWS services which are in use over here are; 

- Amazon Certificate Manager for a https certificate

- Application Load Balancer.

- Set of EC2 instances for Tomcat, Memcache RabbitMQ and mysql

- Three separate security groups

- Amazon Route 53 for DNS Private Zones

- Amazon S3 bucket to store our software artifacts.


We will start the execution now, and this is the flow of execution, 

## FLOW OF EXECUTION

- First, we will log into our AWS account.

- We're going to create key pairs, which we will use to login to our EC2 instances.

- We create security groups for load balancer, Tomcat and backend services. 

- We will launch instances with user data, which will be our bash scripts. 

- We will update IP to name mapping in Route 53.

- We're going to then build our application from source code, this we will do on our local machine, on our laptop.

- Then we upload our artifact to a s3 bucket. 

- From S3 bucket we will download our artifact to Ec2 instance, where tomcat service will be running.

- Then we'll set up a load balancer with https connection.

- We will map our elastic load balancer endpoint to a website name in GoDaddy DNS 

- And we will verify. 

- Once we verified our entire set up, then we'll build an auto scaling group for a Tomcat instances.

So now it's time to dive into AWS.


